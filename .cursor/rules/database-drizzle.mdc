---
alwaysApply: true
---
# Note -> No longer using the Python FastAPI backend for this project. The code is still available in the `backend/` directory, but it is not being maintained. 

# Note -> No longer using supabase for this project. The code is still available in the `supabase/` directory, but it is not being maintained, only using it for the authentication layer on the frontend
& Rust backend  

# Database & Drizzle ORM Guidelines

## Database Architecture

### Multi-Database Strategy
- **Browser SQLite**: Local storage with Drizzle ORM for offline functionality
- **PostgreSQL**: Server-side database with Supabase for production data
- **Edge Functions**: External API integrations and data processing

### Schema Organization
- Browser schemas in `lib/drizzle/` directory
- PostgreSQL schemas in `Database/` directory with numbered folders
- Supabase migrations in `supabase/migrations/`

## Drizzle ORM Patterns

### Schema Definition
```typescript
// Good: Proper schema definition with types
import { sqliteTable, text, integer, real, primaryKey } from 'drizzle-orm/sqlite-core';
import { sql } from 'drizzle-orm';

export const journalTable = sqliteTable('journal_trades', {
  id: integer('id').primaryKey({ autoIncrement: true }),
  userId: text('user_id').notNull(),
  symbol: text('symbol').notNull(),
  assetType: text('asset_type').notNull().$type<AssetTypeEnum>(),
  entryPrice: real('entry_price').notNull(),
  createdAt: text('created_at').notNull().default(sql`(datetime('now'))`),
});
```

### Type Safety
```typescript
// Good: Type inference from schema
export type JournalTrade = typeof journalTable.$inferSelect;
export type NewJournalTrade = typeof journalTable.$inferInsert;

// Good: Enum-like constants
export const TradeType = {
  BUY: 'BUY',
  SELL: 'SELL'
} as const;

export type TradeTypeEnum = typeof TradeType[keyof typeof TradeType];
```

### Database Operations
```typescript
// Good: Proper query patterns
export async function getTradesByUser(userId: string): Promise<JournalTrade[]> {
  return await db
    .select()
    .from(journalTable)
    .where(eq(journalTable.userId, userId))
    .orderBy(desc(journalTable.createdAt));
}

// Good: Insert with proper typing
export async function createTrade(trade: NewJournalTrade): Promise<JournalTrade> {
  const [newTrade] = await db
    .insert(journalTable)
    .values(trade)
    .returning();
  return newTrade;
}
```

### Indexes and Performance
```typescript
// Good: Define indexes for performance
export const journalIndexes = {
  userIdIndex: sql`CREATE INDEX IF NOT EXISTS idx_journal_user_id ON journal_trades(user_id)`,
  symbolIndex: sql`CREATE INDEX IF NOT EXISTS idx_journal_symbol ON journal_trades(symbol)`,
  entryDateIndex: sql`CREATE INDEX IF NOT EXISTS idx_journal_entry_date ON journal_trades(entry_date)`,
};
```

## PostgreSQL Patterns

### Function Organization
- `01_Tables/` - Table definitions
- `02_Upsert_functions/` - Insert/update operations
- `03_Delete_functions/` - Delete operations
- `04_Select_functions/` - Query operations
- `05_Stocks_function/` - Stock-specific functions
- `06_Options_function/` - Options-specific functions

### SQL Function Patterns
```sql
-- Good: Proper function definition
CREATE OR REPLACE FUNCTION get_user_trades(
    p_user_id UUID,
    p_limit INTEGER DEFAULT 50,
    p_offset INTEGER DEFAULT 0
)
RETURNS TABLE (
    id INTEGER,
    symbol TEXT,
    entry_price DECIMAL,
    created_at TIMESTAMP
) AS $$
BEGIN
    RETURN QUERY
    SELECT 
        t.id,
        t.symbol,
        t.entry_price,
        t.created_at
    FROM journal_trades t
    WHERE t.user_id = p_user_id
    ORDER BY t.created_at DESC
    LIMIT p_limit
    OFFSET p_offset;
END;
$$ LANGUAGE plpgsql;
```

### Migration Patterns
```sql
-- Good: Proper migration structure
-- Migration: 20241201_create_journal_trades
CREATE TABLE IF NOT EXISTS journal_trades (
    id SERIAL PRIMARY KEY,
    user_id UUID NOT NULL REFERENCES auth.users(id),
    symbol TEXT NOT NULL,
    asset_type TEXT NOT NULL CHECK (asset_type IN ('STOCK', 'OPTION')),
    trade_type TEXT NOT NULL CHECK (trade_type IN ('BUY', 'SELL')),
    entry_price DECIMAL(10,2) NOT NULL,
    created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Create indexes
CREATE INDEX IF NOT EXISTS idx_journal_user_id ON journal_trades(user_id);
CREATE INDEX IF NOT EXISTS idx_journal_symbol ON journal_trades(symbol);
```

## Data Synchronization

### Browser to Server Sync
```typescript
// Good: Sync pattern for offline-first approach
export async function syncTradesToServer(trades: JournalTrade[]) {
  const pendingTrades = trades.filter(trade => !trade.synced);
  
  for (const trade of pendingTrades) {
    try {
      await fetch('/api/trades', {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify(trade),
      });
      
      // Mark as synced
      await markTradeAsSynced(trade.id);
    } catch (error) {
      console.error('Failed to sync trade:', error);
    }
  }
}
```

### Conflict Resolution
- Use timestamps for conflict detection
- Implement last-write-wins strategy
- Provide user feedback for conflicts
- Maintain audit trail for changes

## Query Optimization

### Efficient Queries
```typescript
// Good: Use proper joins and filters
export async function getTradesWithStats(userId: string) {
  return await db
    .select({
      trade: journalTable,
      stats: sql<number>`COUNT(*) OVER()`.as('total_count'),
    })
    .from(journalTable)
    .where(eq(journalTable.userId, userId))
    .limit(50);
}

// Good: Use prepared statements for repeated queries
const getUserTrades = db
  .select()
  .from(journalTable)
  .where(eq(journalTable.userId, placeholder('userId')))
  .prepare();
```

### Pagination Patterns
```typescript
// Good: Cursor-based pagination
export async function getTradesPaginated(
  userId: string,
  cursor?: string,
  limit = 50
) {
  const query = db
    .select()
    .from(journalTable)
    .where(eq(journalTable.userId, userId))
    .orderBy(desc(journalTable.createdAt))
    .limit(limit + 1);

  if (cursor) {
    query.where(lt(journalTable.createdAt, cursor));
  }

  const trades = await query;
  const hasNextPage = trades.length > limit;
  const nextCursor = hasNextPage ? trades[limit - 1].createdAt : null;

  return {
    trades: trades.slice(0, limit),
    nextCursor,
    hasNextPage,
  };
}
```

## Error Handling

### Database Errors
```typescript
// Good: Proper error handling
export async function createTrade(trade: NewJournalTrade) {
  try {
    const [newTrade] = await db
      .insert(journalTable)
      .values(trade)
      .returning();
    return { success: true, data: newTrade };
  } catch (error) {
    if (error instanceof Error) {
      return { success: false, error: error.message };
    }
    return { success: false, error: 'Unknown database error' };
  }
}
```

### Transaction Management
```typescript
// Good: Use transactions for atomic operations
export async function createTradeWithNotes(
  trade: NewJournalTrade,
  notes: string[]
) {
  return await db.transaction(async (tx) => {
    const [newTrade] = await tx
      .insert(journalTable)
      .values(trade)
      .returning();

    if (notes.length > 0) {
      await tx.insert(notesTable).values(
        notes.map(note => ({
          tradeId: newTrade.id,
          content: note,
        }))
      );
    }

    return newTrade;
  });
}
```

## Security Considerations

### Data Validation
- Validate all inputs before database operations
- Use parameterized queries to prevent SQL injection
- Implement proper access controls
- Sanitize user inputs

### Access Patterns
```typescript
// Good: User-scoped queries
export async function getUserTrade(userId: string, tradeId: number) {
  return await db
    .select()
    .from(journalTable)
    .where(
      and(
        eq(journalTable.id, tradeId),
        eq(journalTable.userId, userId)
      )
    )
    .limit(1);
}
```

## Performance Monitoring

### Query Performance
- Monitor slow queries
- Use proper indexes
- Implement query caching where appropriate
- Profile database operations

### Connection Management
- Use connection pooling
- Implement proper connection lifecycle
- Monitor connection usage
- Handle connection failures gracefully